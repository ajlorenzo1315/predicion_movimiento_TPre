{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378a9489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.virtualenvs/depth/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ali/.virtualenvs/depth/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/ali/.virtualenvs/depth/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/ali/.virtualenvs/depth/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    }
   ],
   "source": [
    "from me_model import Me_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c468a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Arguments_tracker():\n",
    "    \n",
    "    track_thresh:float\n",
    "    track_buffer:int\n",
    "    match_thresh:float\n",
    "    aspect_ratio_thresh:float\n",
    "    min_box_area:int\n",
    "    mot20:bool\n",
    "    frame_rate:int\n",
    "        \n",
    "@dataclass\n",
    "class Arguments_depth():\n",
    "    \n",
    "     checkpoint:str\n",
    "        \n",
    "@dataclass\n",
    "class Arguments_detection():\n",
    "    \n",
    "    config:str\n",
    "    checkpoint:str\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbdac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_track = Arguments_tracker(0.20,30,0.5,1.6,10,False,30)\n",
    "\n",
    "config=\"configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco.py\"\n",
    "checkpoint = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "args_dect=Arguments_detection(config,checkpoint)\n",
    "\n",
    "checkpoint = 'best_model_kitti.ckpt'\n",
    "args_depth=Arguments_depth(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc2d1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n"
     ]
    }
   ],
   "source": [
    "me_modelo_p=Me_model(args_dect,args_depth,args_track,[0,0,8*40],\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b615c2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths= \"./test_3_255-389\"\n",
    "\n",
    "results=[]\n",
    "paths_out=\"test3/prueba_2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31857533",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/Desktop/avanzada_vision_artificial/segmentation/mmdetection-master/demo/mmdet/datasets/utils.py:66: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  warnings.warn(\n",
      "/home/ali/.virtualenvs/depth/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'punto' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mme_modelo_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchange_view\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpaths_out\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/avanzada_vision_artificial/segmentation/mmdetection-master/demo/me_model.py:282\u001b[0m, in \u001b[0;36mMe_model.change_view\u001b[0;34m(self, path, paths_out, ext, save)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[38;5;66;03m#print(np.max(np.array(online_depth)))\u001b[39;00m\n\u001b[1;32m    278\u001b[0m timer\u001b[38;5;241m.\u001b[39mtoc()\n\u001b[0;32m--> 282\u001b[0m image_depth_human\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_x_y_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43monline_tlwhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43monline_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43monline_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolormapped_im\u001b[49m\u001b[43m,\u001b[49m\u001b[43monline_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(image_depth_human)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    285\u001b[0m     image_depth_human,puntos\u001b[38;5;241m=\u001b[39mimage_depth_human\n",
      "File \u001b[0;32m~/Desktop/avanzada_vision_artificial/segmentation/mmdetection-master/demo/me_model.py:176\u001b[0m, in \u001b[0;36mMe_model.pos_x_y_new\u001b[0;34m(self, boxs, ids, masks, depth, depths, frame, view)\u001b[0m\n\u001b[1;32m    174\u001b[0m str_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(frame),\u001b[38;5;28mstr\u001b[39m(ids[idx_box]),\u001b[38;5;28mstr\u001b[39m(puntos[idx_box][\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(puntos[idx_box][\u001b[38;5;241m1\u001b[39m])])\n\u001b[1;32m    175\u001b[0m dep_r\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpixel2reald(puntos_real[idx_box][\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 176\u001b[0m str_save2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(frame),\u001b[38;5;28mstr\u001b[39m(ids[idx_box]),\u001b[38;5;28mstr\u001b[39m(puntos_real[idx_box][\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(puntos_real[idx_box][\u001b[38;5;241m1\u001b[39m]),\u001b[38;5;28mstr\u001b[39m(\u001b[43mpunto\u001b[49m),\u001b[38;5;28mstr\u001b[39m(dep_r)])\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfichero\u001b[38;5;241m.\u001b[39mwrite(str_save \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mlinesep)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfichero2\u001b[38;5;241m.\u001b[39mwrite(str_save2 \u001b[38;5;241m+\u001b[39m os\u001b[38;5;241m.\u001b[39mlinesep)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'punto' is not defined"
     ]
    }
   ],
   "source": [
    "me_modelo_p.change_view(paths,paths_out,\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5215c4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
